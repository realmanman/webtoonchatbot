import os
import pandas as pd
import streamlit as st
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma, FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQAWithSourcesChain
from langchain.memory import ConversationBufferMemory
from langchain.prompts import ChatPromptTemplate

from typing import Literal, Optional
from pydantic import BaseModel, Field, ValidationError
from langchain.output_parsers import PydanticOutputParser
from langchain.prompts import ChatPromptTemplate
from datetime import datetime, timezone
from pathlib import Path
import json, csv

import re

import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

try:
    from zoneinfo import ZoneInfo  # Python 3.9+
    _KST = ZoneInfo("Asia/Seoul")
except Exception:
    _KST = timezone.utc  # í´ë°± (UTC)
####################################################################################

# OpenAI API Key ë“±ë¡
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. .envì— ì„¤ì •í•´ ì£¼ì„¸ìš”.")

# ë³¸ë¬¸ ë‹µë³€ìš© LLM ì„¤ì •
llm = ChatOpenAI(model="gpt-4o", temperature=0, max_tokens=1024)

# ë¶„ë¥˜/ì¶”ì¶œ ì „ìš©: í•¨ìˆ˜ì½œ(Structured Output) LLM
llm_struct = ChatOpenAI(model="gpt-4o-mini", temperature=0, max_tokens=256)

# Intent ê²°ê³¼ ìŠ¤í‚¤ë§ˆ ì •ì˜ (ë¡œê·¸/ë¶„ì„)
# ---------- Pydantic Schemas ----------
class IntentResult(BaseModel):
    intent: Literal["ë²•ë¥ ", "ì •ë³´", "í˜„í™©", "ì¶”ì²œ"]
    confidence: float = Field(ge=0.0, le=1.0)
    reasons: str

class FilterResult(BaseModel):
    # ë¹„ì–´ ìˆì„ ìˆ˜ë„ ìˆìœ¼ë‹ˆ Optional[str]
    ì¹´í…Œê³ ë¦¬: Optional[str] = ""
    ì—°ë ¹ì¸µ: Optional[Literal["10~20ëŒ€", "30ëŒ€", "40ëŒ€", ""]] = ""
    ì„±ë³„: Optional[Literal["ë‚¨ì„±", "ì—¬ì„±", ""]] = ""

# Pydanticìœ¼ë¡œ ì§ì ‘ íŒŒì‹±ë˜ëŠ” ë˜í¼ (íˆ´ì½œ ì‚¬ìš©)
intent_llm = llm_struct.with_structured_output(IntentResult)
filter_llm = llm_struct.with_structured_output(FilterResult)

# DB ê²½ë¡œ
WEBTOON_CSV_PATH = "./webtoon_data.csv" # ì›¹íˆ° í†µê³„ ë²¡í„°DB
CHROMA_DIR = "./chroma_db5"      # ë²•ë¥ /ê°€ì´ë“œ ë¬¸ì„œ ë²¡í„°DB
FAISS_DB_DIR = "./db"            # webtoon_synopsis.csv ê¸°ë°˜ FAISS ë””ë ‰í† ë¦¬

@st.cache_resource
def build_or_load_vectorstores():
    # ---- 1) CSV ë¡œë“œ (í•„ìˆ˜ ì»¬ëŸ¼ ìœ íš¨ì„± ì ê²€) ----
    df = pd.read_csv(WEBTOON_CSV_PATH)
    if "ì¡°íšŒìˆ˜" in df.columns and "êµ¬ë…ììˆ˜" not in df.columns:
        df = df.rename(columns={"ì¡°íšŒìˆ˜": "êµ¬ë…ììˆ˜"})
    # ì•ˆì „í•œ ê¸°ë³¸ ì»¬ëŸ¼ ì²´í¬
    for col in ["ì œëª©", "í‰ì ", "êµ¬ë…ììˆ˜"]:
        if col not in df.columns:
            st.warning(f"CSVì— '{col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆì–´ìš”.")

    # ---- 2) ë²•ë¥ /ê°€ì´ë“œ ë¬¸ì„œìš© Chroma ----
    # ì—†ìœ¼ë©´ ê·¸ëƒ¥ ë¹ˆ DBì—¬ë„ ë˜ì§€ë§Œ, ìµœì†Œ í´ë” ìƒì„±
    Path(CHROMA_DIR).mkdir(parents=True, exist_ok=True)
    embeddings_hf = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-base")
    vectordb = Chroma(persist_directory=CHROMA_DIR, embedding_function=embeddings_hf)
    retriever_law = vectordb.as_retriever(search_kwargs={"k": 5})
    rag_chain_law = RetrievalQAWithSourcesChain.from_chain_type(llm=llm, retriever=retriever_law)

    # ---- 3) ì›¹íˆ° ì •ë³´ìš© FAISS (ì—†ìœ¼ë©´ CSVì—ì„œ ì¦‰ì‹œ ë¹Œë“œ) ----
    faiss_path = Path(FAISS_DB_DIR)
    if faiss_path.exists() and any(faiss_path.iterdir()):
        embedding_info = OpenAIEmbeddings(model="text-embedding-3-small")
        vectorstore_info = FAISS.load_local(FAISS_DB_DIR, embedding_info, allow_dangerous_deserialization=True)
    else:
        # CSV ê° í–‰ì„ í•˜ë‚˜ì˜ ë¬¸ì„œë¡œ ì„ë² ë”©í•˜ì—¬ ì •ë³´ ê²€ìƒ‰ ê°€ëŠ¥í•˜ê²Œ êµ¬ì„±
        records = []
        for _, row in df.iterrows():
            title = str(row.get("ì œëª©", ""))
            summary = str(row.get("ì¤„ê±°ë¦¬", row.get("í‚¤ì›Œë“œ", "")))
            meta = {k: (None if pd.isna(v) else v) for k, v in row.to_dict().items()}
            content = f"ì œëª©: {title}\nìš”ì•½: {summary}\në©”íƒ€: {meta}"
            records.append(content)
        embedding_info = OpenAIEmbeddings(model="text-embedding-3-small")
        vectorstore_info = FAISS.from_texts(records, embedding_info)
        vectorstore_info.save_local(FAISS_DB_DIR)

    retriever_info = vectorstore_info.as_retriever(search_kwargs={"k": 5})
    memory_info = ConversationBufferMemory(memory_key="chat_history", return_messages=True, output_key="answer")

    return df, rag_chain_law, vectordb, retriever_info, memory_info

df, rag_chain, vectordb, retriever_info, memory_info = build_or_load_vectorstores()

# ---------- í”„ë¡¬í”„íŠ¸ ----------
intent_prompt = ChatPromptTemplate.from_messages([
    ("system",
     """ë„ˆëŠ” ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ì •í™•íˆ ë¶„ë¥˜í•œë‹¤.
ê·œì¹™:
- "ë²•ë¥ ": 2ì°¨ ì°½ì‘(ë“œë¼ë§ˆ/ì˜í™”/ê²Œì„/ì• ë‹ˆ ë“±) ê´€ë ¨ ì €ì‘ê¶Œ/ê³„ì•½/ë²•ë ¹/ë²•ì  ì´ìŠˆ ë¬¸ì˜
- "ì •ë³´": ì‘í’ˆ ìì²´ ì •ë³´(ì œëª©/ì¤„ê±°ë¦¬/ì‘ê°€/ë“±ì¥ì¸ë¬¼/ì„¤ì • ë“±)
- "ì¶”ì²œ": 2ì°¨ ì°½ì‘ ëª©ì ì˜ 'ì í•©í•œ ì›¹íˆ° ì¶”ì²œ' ìš”ì²­ (2ì°¨ ì°½ì‘ ì–¸ê¸‰ ì—†ìœ¼ë©´ ì¶”ì²œ ì•„ë‹˜)
- "í˜„í™©": ì¡°íšŒìˆ˜/êµ¬ë…ììˆ˜/í‰ì /ìˆœìœ„/ì—°ë ¹Â·ì„±ë³„ ì„ í˜¸ë„ ë“± í†µê³„Â·ë­í‚¹ ìš”ì²­
"""
),
    ("human", "ì§ˆë¬¸: {question}\ní•˜ë‚˜ì˜ ë¼ë²¨ì„ ê³ ë¥´ê³ , ì‹ ë¢°ë„ì™€ ê°„ë‹¨í•œ ê·¼ê±°ë¥¼ í•¨ê»˜ ë‚´.")
])

filters_prompt = ChatPromptTemplate.from_messages([
    ("system",
     "ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì¶”ì²œ/í˜„í™© ë¶„ì„ì— í•„ìš”í•œ í•„í„°ë¥¼ ì¶”ì¶œí•œë‹¤. "
     "ì¹´í…Œê³ ë¦¬(ììœ  í…ìŠ¤íŠ¸), ì—°ë ¹ì¸µ(10~20ëŒ€/30ëŒ€/40ëŒ€/ë¹ˆ), ì„±ë³„(ë‚¨ì„±/ì—¬ì„±/ë¹ˆ)ì„ ì±„ì›Œë¼."),
    ("human", "ì§ˆë¬¸: {question}")
])

def _strip_code_fences(text: str) -> str:
    t = text.strip()
    # ```json ... ``` or ``` ... ```
    if t.startswith("```"):
        t = re.sub(r"^```(?:json)?\s*", "", t, flags=re.IGNORECASE)
        t = re.sub(r"\s*```$", "", t)
    return t.strip()

def _regex_salvage(text: str) -> dict | None:
    """
    í‚¤ ë”°ì˜´í‘œê°€ ë§ê°€ì§„ ê²½ìš°ê¹Œì§€ ê¸ì–´ì˜¤ê¸° ìœ„í•œ ë§ˆì§€ë§‰ ìˆ˜ë‹¨.
    intent|confidence|reasons í‚¤ë¥¼ ê´€ëŒ€í•˜ê²Œ íƒì§€.
    """
    t = _strip_code_fences(text)
    # ì¤‘ê´„í˜¸ ë¸”ë¡ë§Œ ë¨¼ì € ì¶”ì¶œ
    m = re.search(r'\{.*\}', t, flags=re.DOTALL)
    if m:
        t = m.group(0)
    # í‚¤:ê°’ íŒ¨í„´ ëŠìŠ¨í•˜ê²Œ ë§¤ì¹­ (ë”°ì˜´í‘œ ìœ ë¬´ í—ˆìš©)
    kv = {}
    for key in ["intent", "confidence", "reasons"]:
        # ì˜ˆ: "''intent''" : "ì¶”ì²œ"  ë˜ëŠ”  intent: ì¶”ì²œ
        p = rf'["\'\s]*{key}["\'\s]*\s*:\s*(".*?"|\d+(\.\d+)?|true|false|null|[^,}}]+)'
        mm = re.search(p, t, flags=re.IGNORECASE|re.DOTALL)
        if mm:
            rawv = mm.group(1).strip()
            # ê°’ì—ì„œ ê°ì‹¼ ë”°ì˜´í‘œ ì œê±°
            if rawv.startswith('"') and rawv.endswith('"'):
                rawv = rawv[1:-1]
            kv[key] = rawv
    return kv or None

def _normalize_quoted_keys(obj: dict) -> dict:
    norm = {}
    for k, v in obj.items():
        kk = str(k)
        # ì•ë’¤ ì¤‘ë³µ ë”°ì˜´í‘œ/ê³µë°± ì œê±°  e.g. "'\"intent\"'" â†’ intent
        kk = re.sub(r'^[\s\'"]+|[\s\'"]+$', "", kk)
        norm[kk] = v
    return norm

def tolerant_pydantic_parse(text: str, model_cls: type[BaseModel]):
    # 0) ê·¸ëŒ€ë¡œ
    for candidate in [text, _strip_code_fences(text)]:
        try:
            return model_cls.parse_obj(json.loads(candidate))
        except Exception:
            pass
        # ë‹¨ì¼ë”°ì˜´í‘œ â†’ ì´ì¤‘ë”°ì˜´í‘œ
        try:
            t2 = candidate.replace("'", '"')
            obj = json.loads(t2)
            obj = _normalize_quoted_keys(obj)
            return model_cls.parse_obj(obj)
        except Exception:
            pass

    # 1) ""intent"" â†’ "intent" êµì •
    t3 = re.sub(r'"{2,}\s*([A-Za-z_][\w\- ]*)\s*"{2,}\s*:', r'"\1":', text)
    try:
        obj = json.loads(_strip_code_fences(t3))
        obj = _normalize_quoted_keys(obj)
        return model_cls.parse_obj(obj)
    except Exception:
        pass

    # 2) ì •ê·œì‹ êµ¬ì¡°í™”(ìµœí›„ ìˆ˜ë‹¨)
    salvaged = _regex_salvage(text)
    if salvaged:
        try:
            # ê²°ì¸¡ ë³´ì •
            if "confidence" in salvaged:
                try:
                    salvaged["confidence"] = float(salvaged["confidence"])
                except Exception:
                    salvaged["confidence"] = 0.0
            salvaged.setdefault("reasons", "")
            # intent ë¼ë²¨ ì •ê·œí™”
            if "intent" in salvaged:
                lbl = salvaged["intent"].strip()
                # ì˜¤íƒ€/ì˜ë¬¸ ëŒ€ì‘
                mapping = {
                    "ë²•ë¥ ":"ë²•ë¥ ", "legal":"ë²•ë¥ ",
                    "ì •ë³´":"ì •ë³´", "info":"ì •ë³´",
                    "í˜„í™©":"í˜„í™©", "status":"í˜„í™©", "í†µê³„":"í˜„í™©",
                    "ì¶”ì²œ":"ì¶”ì²œ", "recommend":"ì¶”ì²œ"
                }
                salvaged["intent"] = mapping.get(lbl.lower(), lbl)
            return model_cls.parse_obj(salvaged)
        except Exception:
            pass

    return None

# ---------- ì˜ë„ ë¶„ë¥˜ + ë¡œê·¸ ì €ì¥ ----------
INTENT_LOG_PATH = Path("./intent_logs.csv")

def _now_kst_str() -> str:
    return datetime.now(tz=_KST).strftime("%Y-%m-%d %H:%M:%S%z")

def log_intent_row(question: str, res: IntentResult, raw_payload: str = ""):
    write_header = not INTENT_LOG_PATH.exists()
    with INTENT_LOG_PATH.open("a", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        if write_header:
            w.writerow(["timestamp_kst","question","intent","confidence","reasons","raw"])
        w.writerow([_now_kst_str(), question, res.intent, f"{res.confidence:.3f}", res.reasons, raw_payload])

def _rule_based_fallback(q: str, default: str = "ì •ë³´") -> str:
    ql = q.lower()
    law_kw = ["ì €ì‘ê¶Œ","ë²•","ë²•ë¥ ","ê³„ì•½","ì´ˆìƒê¶Œ","í—ˆê°€","ë¼ì´ì„ ìŠ¤","ë“œë¼ë§ˆí™”","ì˜í™”í™”","ê°ìƒ‰","íŒê¶Œ","ip","ë¦¬ë©”ì´í¬","ì›ì‘ ê³„ì•½","ì„­ì™¸"]
    status_kw = ["ì¡°íšŒìˆ˜","êµ¬ë…ììˆ˜","í‰ì ","ë­í‚¹","ìˆœìœ„","ì„ í˜¸ë„","í†µê³„"]
    rec_kw = ["ì¶”ì²œ","ê³¨ë¼ì¤˜","í”½","ê³ ë¥´ë©´","ì¶”ì²œí•´","ê³¨ë¼","ë­˜ ë³¼ê¹Œ","ì¶”ì²œ ì¢€"]
    if any(k in q for k in law_kw): return "ë²•ë¥ "
    if any(k in q for k in status_kw): return "í˜„í™©"
    if ("ë“œë¼ë§ˆ" in q or "ì˜í™”" in q or "ê²Œì„" in q or "ì• ë‹ˆ" in q) and any(k in ql for k in rec_kw): return "ì¶”ì²œ"
    if any(k in ql for k in rec_kw): return "ì¶”ì²œ"
    return default

# ---------- ë¶„ë¥˜ ----------
def classify_intent(question: str, confidence_threshold: float = 0.5) -> str:
    # 1) í•¨ìˆ˜ì½œ ê¸°ë°˜ Structured Output (íŒŒì‹± ì‹¤íŒ¨ ê±°ì˜ ì—†ìŒ)
    msgs = intent_prompt.format_messages(question=question)
    res: IntentResult = intent_llm.invoke(msgs)
    intent = res.intent
    conf = max(0.0, min(1.0, float(res.confidence)))

    # 2) ì•½í•˜ë©´ ë£° ë³´ì •
    if conf < confidence_threshold:
        intent = _rule_based_fallback(question, default=intent)

    # 3) ì›ë¬¸ ë¡œê·¸: í•¨ìˆ˜ì½œì—ì„  raw JSONì´ ì—†ìœ¼ë‹ˆ, ëª¨ë¸ ì…ë ¥(ì§ˆë¬¸)ê³¼ ë„ì¶œê°’ì„ JSONì²˜ëŸ¼ ê¸°ë¡
    raw_payload = f'{{"intent":"{res.intent}", "confidence":{res.confidence}, "reasons":"{res.reasons}"}}'
    log_intent_row(question, res, raw_payload=raw_payload)
    return intent

def extract_filters_structured(question: str) -> dict:
    raw = ""
    try:
        msgs = filters_prompt.format_messages(
            format_instructions=filter_parser.get_format_instructions(),
            question=question,
        )
        resp = llm_struct.invoke(msgs)  # âœ… JSON ê°•ì œ
        raw = resp.content or ""

        try:
            parsed: FilterResult = filter_parser.parse(raw)
        except Exception:
            parsed = tolerant_pydantic_parse(raw, FilterResult)
            if parsed is None:
                raise KeyError('filters_parse_failed')

        return parsed.dict()

    except Exception:
        # í´ë°±
        cond = {"ì¹´í…Œê³ ë¦¬": "", "ì—°ë ¹ì¸µ": "", "ì„±ë³„": ""}
        cats = ["ë¡œë§¨ìŠ¤", "ë“œë¼ë§ˆ", "ì•¡ì…˜", "ë¬´í˜‘", "ìŠ¤ë¦´ëŸ¬", "íŒíƒ€ì§€", "ì½”ë¯¸ë””", "í•™ì›", "ìŠ¤í¬ì¸ ", "ê³µí¬"]
        for c in cats:
            if c in question:
                cond["ì¹´í…Œê³ ë¦¬"] = c
                break
        if any(k in question for k in ["10ëŒ€", "20ëŒ€", "10~20ëŒ€", "ì Šì€", "ì²­ì†Œë…„", "Zì„¸ëŒ€"]):
            cond["ì—°ë ¹ì¸µ"] = "10~20ëŒ€"
        elif "30ëŒ€" in question or "ì§ì¥ì¸" in question:
            cond["ì—°ë ¹ì¸µ"] = "30ëŒ€"
        elif "40ëŒ€" in question:
            cond["ì—°ë ¹ì¸µ"] = "40ëŒ€"
        if "ì—¬ì„±" in question or "ì—¬ì" in question:
            cond["ì„±ë³„"] = "ì—¬ì„±"
        elif "ë‚¨ì„±" in question or "ë‚¨ì" in question:
            cond["ì„±ë³„"] = "ë‚¨ì„±"
        return cond        

# ---- Intent/íŒŒì‹± ê³ ë„í™” ----
prompt_template_info = ChatPromptTemplate.from_messages([
    ("system", "ë„ˆëŠ” ì›¹íˆ° ì „ë¬¸ê°€ì•¼. ë°˜ë“œì‹œ ì›¹íˆ° ë°ì´í„°ë² ì´ìŠ¤(ê²€ìƒ‰ ë¬¸ì„œ) ë‚´ ì •ë³´ë§Œ ì‚¬ìš©í•´. \
ë¬¸ì„œê°€ ì—†ìœ¼ë©´ 'í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'ë¼ê³ ë§Œ ë§í•´."),
    ("human", "ì§ˆë¬¸: {question}\n\nê´€ë ¨ ë¬¸ì„œ:\n{context}")
])

def custom_rag_chatbot(query, retriever, llm, memory):
    docs = retriever.get_relevant_documents(query)
    if not docs:
        return "í•´ë‹¹ ì •ë³´ë¥¼ ì›¹íˆ° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›¹íˆ°ê³¼ ê´€ë ¨ëœ ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”."
    context = "\n\n".join([d.page_content for d in docs])
    messages = prompt_template_info.format_messages(question=query, context=context)
    response = llm(messages)
    memory.chat_memory.add_user_message(query)
    memory.chat_memory.add_ai_message(response.content)
    return response.content

def extract_top_k(question: str, default_k=5) -> int:
    # ìˆ«ì + (ê°œ|í¸|ëª…|ìœ„|top) íŒ¨í„´ ë‹¤ì–‘í™”
    m = re.search(r"(?:ìƒìœ„|top\s*)?(\d+)\s*(?:ê°œ|í¸|ëª…|ìœ„)?", question, re.IGNORECASE)
    if m:
        try:
            n = int(m.group(1))
            return max(1, min(5, n))
        except:
            pass
    return default_k

def _safe_contains(series: pd.Series, needle: str) -> pd.Series:
    if not needle:
        return pd.Series([True]*len(series), index=series.index)
    return series.fillna("").astype(str).str.contains(needle, case=False, na=False)

def handle_recommendation(question: str) -> str:
    k = extract_top_k(question, default_k=5)
    cond = extract_filters_structured(question)
    filtered = df.copy()

    if "ì¹´í…Œê³ ë¦¬" in df.columns and cond["ì¹´í…Œê³ ë¦¬"]:
        filtered = filtered[_safe_contains(filtered["ì¹´í…Œê³ ë¦¬"], cond["ì¹´í…Œê³ ë¦¬"])]

    # ì—°ë ¹ì¸µ/ì„±ë³„ ê´€ë ¨ ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ìš°íšŒ
    if cond["ì—°ë ¹ì¸µ"] in df.columns:
        filtered = filtered[_safe_contains(filtered[cond["ì—°ë ¹ì¸µ"]], "ìƒ|ì¤‘")]
    if "ì„±ë³„ì„ í˜¸ë„" in df.columns and cond["ì„±ë³„"]:
        filtered = filtered[_safe_contains(filtered["ì„±ë³„ì„ í˜¸ë„"], cond["ì„±ë³„"])]

    if filtered.empty:
        return "â— ì¡°ê±´ì— ë§ëŠ” ì›¹íˆ°ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    # ê°„ë‹¨ ì ìˆ˜ì‹ (ê°€ì¤‘ì¹˜ ìƒìˆ˜ëŠ” ì„¤ì •ê°’í™” ê°€ëŠ¥)
    score = []
    for _, row in filtered.iterrows():
        rating = float(row.get("í‰ì ", 0) or 0)
        subs = float(row.get("êµ¬ë…ììˆ˜", 0) or 0)
        score.append(rating * 1.0 + (subs / 1000.0))
    filtered = filtered.assign(ì¶”ì²œì ìˆ˜=score).sort_values("ì¶”ì²œì ìˆ˜", ascending=False).head(k)

    lines = []
    for _, r in filtered.iterrows():
        title = r.get("ì œëª©", "N/A")
        rating = r.get("í‰ì ", "N/A")
        subs = int(float(r.get("êµ¬ë…ììˆ˜", 0)))
        kw = r.get("í‚¤ì›Œë“œ", "")
        lines.append(f"- {title} (í‰ì : {rating}, êµ¬ë…ììˆ˜: {subs}, í‚¤ì›Œë“œ: {kw})")
    return "\n".join(lines)

def handle_status(question: str) -> str:
    k = extract_top_k(question, default_k=5)
    cond = extract_filters_structured(question)
    filtered = df.copy()

    if "ì¹´í…Œê³ ë¦¬" in df.columns and cond["ì¹´í…Œê³ ë¦¬"]:
        filtered = filtered[_safe_contains(filtered["ì¹´í…Œê³ ë¦¬"], cond["ì¹´í…Œê³ ë¦¬"])]
    if cond["ì—°ë ¹ì¸µ"] in df.columns:
        filtered = filtered[_safe_contains(filtered[cond["ì—°ë ¹ì¸µ"]], "ìƒ|ì¤‘")]
    if "ì„±ë³„ì„ í˜¸ë„" in df.columns and cond["ì„±ë³„"]:
        filtered = filtered[_safe_contains(filtered["ì„±ë³„ì„ í˜¸ë„"], cond["ì„±ë³„"])]

    # ì •ë ¬ ê¸°ì¤€ ìë™ íŒë³„
    if "êµ¬ë…ììˆ˜" in question:
        key = "êµ¬ë…ììˆ˜"
    elif "í‰ì " in question:
        key = "í‰ì "
    else:
        key = None

    if key and key in filtered.columns:
        top = filtered.sort_values(key, ascending=False).head(k)
    else:
        cols = [c for c in ["í‰ì ", "êµ¬ë…ììˆ˜"] if c in filtered.columns]
        if cols:
            top = filtered.sort_values(cols, ascending=False).head(k)
        else:
            return "â— ì¡°ê±´ì— ë§ëŠ” ì›¹íˆ°ì´ ì—†ìŠµë‹ˆë‹¤."

    lines = []
    for _, r in top.iterrows():
        title = r.get("ì œëª©", "N/A")
        rating = r.get("í‰ì ", "N/A")
        subs = int(float(r.get("êµ¬ë…ììˆ˜", 0)))
        cat = r.get("ì¹´í…Œê³ ë¦¬", "")
        lines.append(f"- {title} (í‰ì : {rating}, êµ¬ë…ììˆ˜: {subs}, ì¹´í…Œê³ ë¦¬: {cat})")
    return "\n".join(lines)



# Streamlit UI
st.title("ğŸ“š ì›¹íˆ° í†µí•© ì±—ë´‡ (ë²•ë¥  + ì •ë³´ + í˜„í™© + ì¶”ì²œ)")
st.caption("2ì°¨ ì°½ì‘ + ë°ì´í„° í†µê³„ + ì›¹íˆ° ì •ë³´ ì œê³µ ì±—ë´‡")

if "history" not in st.session_state:
    st.session_state.history = []

with st.form("input_form", clear_on_submit=True):
    user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: 30ëŒ€ ì—¬ì„±ì´ ì¢‹ì•„í•  ë“œë¼ë§ˆ ì›¹íˆ° ì¶”ì²œí•´ì¤˜")
    submitted = st.form_submit_button("ì§ˆë¬¸í•˜ê¸°")

if submitted and user_input:
    intent = classify_intent(user_input)
    response = ""
    chunks = []

    if intent == "ë²•ë¥ ":
        result = rag_chain(user_input)
        response = result["answer"]
        chunks = vectordb.similarity_search(user_input, k=5)
    elif intent == "í˜„í™©":
        response = handle_status(user_input)
    elif intent == "ì¶”ì²œ":
        response = handle_recommendation(user_input)
    elif intent == "ì •ë³´":
        response = custom_rag_chatbot(user_input, retriever_info, llm, memory_info)
    else:
        response = "â— ì§ˆë¬¸ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

    st.session_state.history.append({
        "ì§ˆë¬¸": user_input,
        "ë‹µë³€": response,
        "intent": intent,
        "chunks": chunks
    })

for chat in reversed(st.session_state.history):
    st.markdown(f"**ğŸ’¬ ì§ˆë¬¸:** {chat['ì§ˆë¬¸']}")
    if chat["intent"] == "ë²•ë¥ ":
        st.markdown("**ğŸ“š ë²•ë¥  ì‘ë‹µ:**")
    elif chat["intent"] == "í˜„í™©":
        st.markdown("**ğŸ“Š í˜„í™© ì‘ë‹µ:**")
    elif chat["intent"] == "ì¶”ì²œ":
        st.markdown("**ğŸ¯ ì¶”ì²œ ì‘ë‹µ:**")
    elif chat["intent"] == "ì •ë³´":
        st.markdown("**ğŸ“˜ ì›¹íˆ° ì •ë³´ ì‘ë‹µ:**")
    st.markdown(chat['ë‹µë³€'].replace("\n", "  \n"))
    st.divider()